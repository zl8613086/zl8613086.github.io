<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="python,爬虫," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="这是我自己写的一个小爬虫程序，爬的是http://www.mnw.cn/news/world/
其实使用正则表达式相对比较简单，需要做的就是看网页源码，看一下你需要的内容然后使用正则将他提取出来。
首先先看一下这个网站以及网站源码
因为网站都是分页的，我们要抓取很多页的时候要知道每一页的url，下面两个图是我分别打开这个网站的首页，和点击第三页以后的url可以看到第一页就是首页地址后面不加任何路径">
<meta property="og:type" content="article">
<meta property="og:title" content="python爬虫">
<meta property="og:url" content="http://yoursite.com/2016/07/26/python爬虫/index.html">
<meta property="og:site_name" content="ZL's blog">
<meta property="og:description" content="这是我自己写的一个小爬虫程序，爬的是http://www.mnw.cn/news/world/
其实使用正则表达式相对比较简单，需要做的就是看网页源码，看一下你需要的内容然后使用正则将他提取出来。
首先先看一下这个网站以及网站源码
因为网站都是分页的，我们要抓取很多页的时候要知道每一页的url，下面两个图是我分别打开这个网站的首页，和点击第三页以后的url可以看到第一页就是首页地址后面不加任何路径">
<meta property="og:image" content="http://i.imgur.com/IERQYru.png">
<meta property="og:image" content="http://i.imgur.com/V7Tn5rA.png">
<meta property="og:image" content="http://i.imgur.com/TmNXpem.png">
<meta property="og:image" content="http://i.imgur.com/irQBvCd.png">
<meta property="og:image" content="http://i.imgur.com/DVrxpaq.png">
<meta property="og:updated_time" content="2016-08-01T11:23:28.647Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python爬虫">
<meta name="twitter:description" content="这是我自己写的一个小爬虫程序，爬的是http://www.mnw.cn/news/world/
其实使用正则表达式相对比较简单，需要做的就是看网页源码，看一下你需要的内容然后使用正则将他提取出来。
首先先看一下这个网站以及网站源码
因为网站都是分页的，我们要抓取很多页的时候要知道每一页的url，下面两个图是我分别打开这个网站的首页，和点击第三页以后的url可以看到第一页就是首页地址后面不加任何路径">
<meta name="twitter:image" content="http://i.imgur.com/IERQYru.png">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 6290473885917775000,
      author: '博主'
    }
  };
</script>

  <title> python爬虫 | ZL's blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">ZL's blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Walk steps step by step</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      
        
        <li class="menu-item menu-item-guestbook">
          <a href="/guestbook" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            留言
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="#" class="st-search-show-outputs">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'SoL_6ZfyzAjPMAMqwSbj','2.0.0');
</script>



    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                python爬虫
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-07-26T12:30:45+08:00" content="2016-07-26">
              2016-07-26
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/07/26/python爬虫/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/07/26/python爬虫/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>这是我自己写的一个小爬虫程序，爬的是<a href="http://www.mnw.cn/news/world/" target="_blank" rel="external">http://www.mnw.cn/news/world/</a></p>
<p>其实使用正则表达式相对比较简单，需要做的就是看网页源码，看一下你需要的内容然后使用正则将他提取出来。</p>
<p>首先先看一下这个网站以及网站源码<br><img src="http://i.imgur.com/IERQYru.png" alt=""></p>
<p>因为网站都是分页的，我们要抓取很多页的时候要知道每一页的url，下面两个图是我分别打开这个网站的首页，和点击第三页以后的url可以看到第一页就是首页地址后面不加任何路径，X页的网页url就是<br><a href="http://www.mnw.cn/news/world/index-X.html" target="_blank" rel="external">http://www.mnw.cn/news/world/index-X.html</a> ,可以用一个简单的if判断加字符串拼接得到每一页的url</p>
<p><img src="http://i.imgur.com/V7Tn5rA.png" alt=""><br><img src="http://i.imgur.com/TmNXpem.png" alt=""></p>
<p>因为我打算使用爬虫将我项目里的资讯数据库进行填充，根据我所需要的资讯内容，我需要爬虫出新闻的<br>图片（无图片的可以为空或者先找一张其他的放在里面）、新闻的标题、新闻的概述、发布者、新闻链接、时间。<br><img src="http://i.imgur.com/irQBvCd.png" alt=""><br>先来看一下使用火狐浏览器的firebug插件抓到的源码，可以看到新闻条目在网页中是</p>
<p>有图片：<code>&lt;div class=&quot;item noimg &quot;&gt;</code></p>
<p>无图片：<code>&lt;div class=&quot;item noimg &quot;&gt;</code></p>
<p>然后使用正则分别抓取以后再在每一条后面单独住取出想要的内容，详情看一下代码。</p>
<p>接下来就是抓取出一共有多少页，可以从下图中很容易看到，并抓取出来。</p>
<p><img src="http://i.imgur.com/DVrxpaq.png" alt=""></p>
<pre><code># -*- coding: utf-8 -*-
#---------------------------------------
#   程序：新闻头条爬虫
#   版本：1.0
#   作者：zl
#   日期：2016-06-16
#   语言：Python 2.7
#   操作：输入网址后自动只看楼主并保存到本地文件
#   功能：将楼主发布的内容打包txt存储到本地。
#---------------------------------------

import string
import urllib2
import re
import MySQLdb
import random

#----------- 处理页面上的各种标签 -----------
class HTML_Tool:
# 用非 贪婪模式 匹配 \t 或者 \n 或者 空格 或者 超链接 或者 图片
BgnCharToNoneRex = re.compile(&quot;(\t|\n| |&lt;a.*?&gt;|&lt;img.*?&gt;)&quot;)

# 用非 贪婪模式 匹配 任意&lt;&gt;标签
EndCharToNoneRex = re.compile(&quot;&lt;.*?&gt;&quot;)

# 用非 贪婪模式 匹配 任意&lt;p&gt;标签
BgnPartRex = re.compile(&quot;&lt;p.*?&gt;&quot;)
CharToNewLineRex = re.compile(&quot;(&lt;br/&gt;|&lt;/p&gt;|&lt;tr&gt;|&lt;div&gt;|&lt;/div&gt;)&quot;)
CharToNextTabRex = re.compile(&quot;&lt;td&gt;&quot;)

# 将一些html的符号实体转变为原始符号
replaceTab = [(&quot;&amp;lt;&quot;,&quot;&lt;&quot;),(&quot;&amp;gt;&quot;,&quot;&gt;&quot;),(&quot;&amp;amp;&quot;,&quot;&amp;&quot;),(&quot;&amp;amp;&quot;,&quot;\&quot;&quot;),(&quot;&amp;nbsp;&quot;,&quot; &quot;),(&quot;&amp;ldquo;&quot;,&apos;\&quot;&apos;),(&quot;&amp;rdquo;&quot;,&apos;\&quot;&apos;)]

def Replace_Char(self,x):
x = self.BgnCharToNoneRex.sub(&quot;&quot;,x)
x = self.BgnPartRex.sub(&quot;\n&quot;,x)
x = self.CharToNewLineRex.sub(&quot;\n&quot;,x)
x = self.CharToNextTabRex.sub(&quot;\t&quot;,x)
x = self.EndCharToNoneRex.sub(&quot;&quot;,x)

for t in self.replaceTab:  
x = x.replace(t[0],t[1])  
return x  

class Toutiao_Spider:
# 申明相关的属性
def __init__(self,url):  
self.myUrl = url
self.datas = []

self.myTool = HTML_Tool()
print u&apos;已经启动头条新闻爬虫，咔嚓咔嚓&apos;

# 初始化加载页面并将其转码储存
def Toutiao_news(self):
# 读取页面的原始信息并将其从utf8转码
myPage = urllib2.urlopen(self.myUrl).read().decode(&quot;utf-8&quot;)
# 计算一共有多少页
endPage = self.page_counter(myPage)   
# 获取最终的数据
title=u&apos;国际新闻&apos;
self.save_data(self.myUrl,title,endPage)

#用来计算一共有多少页
def page_counter(self,myPage):
# 匹配 ? 来获取一共有多少页
#&lt;a href=&quot;http://www.mnw.cn/news/world/index-?.html&quot;&gt;?&lt;/a&gt;

myMatch = re.search(r&apos;&lt;a href=&quot;http://www.mnw.cn/news/world/index-(\d+?).html&quot;&gt;... (\d+?)&lt;/a&gt;&apos;, myPage, re.S)
if myMatch:  
#endPage = int(myMatch.group(1))
endPage=20
print u&apos;爬虫报告：发现楼主共有%d页的原创内容&apos; % endPage
else:
endPage = 0
print u&apos;爬虫报告：无法计算楼主发布内容有多少页！&apos;
return endPage




# 用来存储楼主发布的内容
def save_data(self,url,title,endPage):
# 加载页面数据到数组中
self.get_data(url,endPage)
self.save_mysql();
print u&apos;爬虫报告：文件已下载到本地并打包成txt文件&apos;
print u&apos;请按任意键退出...&apos;
raw_input();



def save_mysql(self):
l=len(self.datas)
try:
conn=MySQLdb.connect(host=&apos;localhost&apos;,user=&apos;root&apos;,passwd=&apos;root&apos;,db=&apos;test&apos;,port=3306,charset=&apos;utf8&apos;)
cur=conn.cursor()
conn.select_db(&apos;toutiao&apos;)
for ml in self.datas:
#print ml[&apos;title&apos;]
#print ml[&apos;html&apos;]
#print ml[&apos;src&apos;]
#print ml[&apos;time&apos;]
#print ml[&apos;content&apos;]
sql = &quot;INSERT INTO news(title,link,image,like_count,comment_count,created_date,user_id,news_content)VALUES (&apos;%s&apos;, &apos;%s&apos;, &apos;%s&apos;, &apos;%s&apos;, &apos;%s&apos;,&apos;%s&apos;,&apos;%s&apos;,&apos;%s&apos; )&quot; \
  %(ml[&apos;title&apos;],ml[&apos;html&apos;],ml[&apos;src&apos;], random.randint(0,10),1,ml[&apos;time&apos;],random.randint(1,8),ml[&apos;content&apos;]) 
cur.execute(sql)
conn.commit()
cur.close()
conn.close()
except MySQLdb.Error,e:
print &quot;Mysql Error %d: %s&quot; % (e.args[0], e.args[1])




# 获取页面源码并将其存储到数组中
def get_data(self,url,endPage):
realurl = url 
for i in range(1,endPage+1):
print u&apos;爬虫报告：爬虫%d号正在加载中...&apos; % i
if i==1:
realurl=url
else:
realurl=url+&apos;index-&apos;+str(i)+&apos;.html&apos;
myPage = urllib2.urlopen(realurl).read()
#print myPage
# 将myPage中的html代码处理并存储到datas里面
self.deal_data(myPage.decode(&apos;utf-8&apos;))
#print self.datas[0][&apos;content&apos;]




# 将内容从页面代码中抠出来
def deal_data(self,myPage):
myItems = re.findall(r&apos;&lt;div class=&quot;item &quot;&gt;(.*?)&lt;/div&gt;&apos;,myPage,re.S)
#print myItems
for item in myItems:
#data = self.myTool.Replace_Char(item.replace(&quot;\n&quot;,&quot;&quot;).encode(&apos;utf-8&apos;))
#print item
matchhtml=re.search(r&apos;href=&quot;(.*?)&quot;&apos;,item,re.S)
if matchhtml:
html=matchhtml.group(1)
else:
html=&apos;&apos;
#print html
matchsrc=re.search(r&apos;src=&quot;(.*?)&quot;&apos;,item,re.S)
if matchsrc:
src=matchsrc.group(1)
else:
src=&apos;&apos;
matchtitle=re.search(r&apos;target=&quot;_blank&quot;&gt;([^\\&lt;]*)&lt;/a&gt;&apos;,item,re.S)
if matchtitle:
title=matchtitle.group(1)
else:
title=&apos;&apos;
matchcontent=re.search(r&apos;&lt;p&gt;\s*([\s\S]*)\s*&lt;/p&gt;&apos;,item,re.S)
if matchcontent:
content=matchcontent.group(1)
else:
content=&apos;&apos;
#print content
matchtime=re.search(r&apos;(\d*)-(\d*)-(\d*) (\d*):(\d*)&apos;,item,re.S)
if matchtime:
time=matchtime.group(1)+&apos;-&apos;+matchtime.group(2)+&apos;-&apos;+matchtime.group(3)+&apos; &apos;+matchtime.group(4)+&apos;:&apos;+matchtime.group(5)
else:
time=&apos;&apos;
info={&apos;html&apos;:html,&apos;src&apos;:src,&apos;title&apos;:title,&apos;content&apos;:self.myTool.Replace_Char(content),&apos;time&apos;:time}
#print info
self.datas.append(info)
#print myPage
myItems = re.findall(r&apos;&lt;div class=&quot;item  noimg &quot;&gt;(.*?)&lt;/div&gt;&apos;,myPage,re.S) 
for item in myItems:
#print item
matchhtml=re.search(r&apos;href=&quot;(.*?)&quot;&apos;,item,re.S)
if matchhtml:
html=matchhtml.group(1)
else:
html=&apos;&apos;
matchtitle=re.search(r&apos;target=&quot;_blank&quot;&gt;([^\\&lt;]*)&lt;/a&gt;&apos;,item,re.S)
if matchtitle:
title=matchtitle.group(1)
else:
title=&apos;&apos;
matchcontent=re.search(r&apos;&lt;p&gt;\s*(.*?)\s*&lt;/p&gt;&apos;,item,re.S)
if matchcontent:
content=matchcontent.group(1)
else:
content=&apos;&apos;
matchtime=re.search(r&apos;(\d*)-(\d*)-(\d*) (\d*):(\d*)&apos;,item,re.S)
if matchtime:
time=matchtime.group(1)+&apos;-&apos;+matchtime.group(2)+&apos;-&apos;+matchtime.group(3)+&apos; &apos;+matchtime.group(4)+&apos;:&apos;+matchtime.group(5)
else:
time=&apos;&apos;
src=&apos;http://images.nowcoder.com/head/%dm.png&apos; %random.randint(1,1000)
info={&apos;html&apos;:html,&apos;src&apos;:src,&apos;title&apos;:title,&apos;content&apos;:self.myTool.Replace_Char(content),&apos;time&apos;:time}
self.datas.append(info)







#-------- 程序入口处 -----------------
print u&quot;&quot;&quot;#--------------------------------
#   程序：新闻头条爬虫
#   版本：1.0
#   作者：zl
#   日期：2016-06-16
#   语言：Python 2.7
#   操作：输入网址后自动只看楼主并保存到本地文件
#   功能：将楼主发布的内容打包txt存储到本地。
#---------------------------------------
&quot;&quot;&quot;


# 以新闻头条国际新闻为例子
# bdurl = &apos;http://www.mnw.cn/news/world/&apos;

#print u&apos;请输入地址最后的数字串：&apos;
tturl = &apos;http://www.mnw.cn/news/world/&apos; 

#调用
mySpider = Toutiao_Spider(tturl)
mySpider.Toutiao_news()
</code></pre>
      
    </div>

    <div>
      
        
      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python/" rel="tag">#python</a>
          
            <a href="/tags/爬虫/" rel="tag">#爬虫</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/07/25/Spring设计模式/" rel="next" title="Spring设计模式">
                <i class="fa fa-chevron-left"></i> Spring设计模式
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/07/27/SpringMvc找Controller/" rel="prev" title="SpringMVC怎么找到Controller">
                SpringMVC怎么找到Controller <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
        <div class="ds-share flat" data-thread-key="2016/07/26/python爬虫/"
     data-title="python爬虫"
     data-content=""
     data-url="http://yoursite.com/2016/07/26/python爬虫/">
  <div class="ds-share-inline">
    <ul  class="ds-share-icons-16">

      <li data-toggle="ds-share-icons-more"><a class="ds-more" href="javascript:void(0);">分享到：</a></li>
      <li><a class="ds-weibo" href="javascript:void(0);" data-service="weibo">微博</a></li>
      <li><a class="ds-qzone" href="javascript:void(0);" data-service="qzone">QQ空间</a></li>
      <li><a class="ds-qqt" href="javascript:void(0);" data-service="qqt">腾讯微博</a></li>
      <li><a class="ds-wechat" href="javascript:void(0);" data-service="wechat">微信</a></li>

    </ul>
    <div class="ds-share-icons-more">
    </div>
  </div>
</div>
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2016/07/26/python爬虫/"
           data-title="python爬虫" data-url="http://yoursite.com/2016/07/26/python爬虫/">
      </div>
    
  </div>

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/1.png"
               alt="ZL" />
          <p class="site-author-name" itemprop="name">ZL</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">37</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">31</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/zl8613086" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <p class="post-toc-empty">此文章未包含目录</p>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ZL</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"zlduoshuo"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
      
      <script src="/vendors/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
      <script src="/js/src/hook-duoshuo.js"></script>
    
  






  
  
  

  

  

</body>
</html>
